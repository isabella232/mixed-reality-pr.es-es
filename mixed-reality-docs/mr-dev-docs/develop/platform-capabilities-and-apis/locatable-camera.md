---
title: Cámara localizable
description: Información general sobre la cámara frontal de HoloLens, cómo funciona y los perfiles y las soluciones disponibles para los desarrolladores.
author: cdedmonds
ms.author: wguyman
ms.date: 06/12/2019
ms.topic: article
keywords: cámara, hololens, cámara de color, frontal cara, hololens 2, CV, Computer Vision, fiducial, Marks, código QR, QR, Foto, vídeo
ms.openlocfilehash: 992258a38b78e9f36e873f7c478d2b6e6f0e3785
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 10/03/2020
ms.locfileid: "91692074"
---
# <a name="locatable-camera"></a><span data-ttu-id="21e2f-104">Cámara localizable</span><span class="sxs-lookup"><span data-stu-id="21e2f-104">Locatable camera</span></span>

<span data-ttu-id="21e2f-105">HoloLens incluye una cámara mundial montada en la parte frontal del dispositivo, lo que permite a las aplicaciones ver lo que ve el usuario.</span><span class="sxs-lookup"><span data-stu-id="21e2f-105">HoloLens includes a world-facing camera mounted on the front of the device, which enables apps to see what the user sees.</span></span> <span data-ttu-id="21e2f-106">Los desarrolladores tienen acceso y control de la cámara, tal como lo harían las cámaras de color en smartphones, portátiles o equipos de escritorio.</span><span class="sxs-lookup"><span data-stu-id="21e2f-106">Developers have access to and control of the camera, just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="21e2f-107">La misma captura universal de Windows [media](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) y las API de Windows Media Foundation que funcionan en Mobile y Desktop funcionan en HoloLens.</span><span class="sxs-lookup"><span data-stu-id="21e2f-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="21e2f-108">Unity [también ha encapsulado estas API de Windows](../unity/locatable-camera-in-unity.md) para simplificar el uso de la cámara en HoloLens para tareas como realizar fotos y vídeos regulares (con o sin hologramas) y buscar la posición de la cámara en y en la perspectiva de la escena.</span><span class="sxs-lookup"><span data-stu-id="21e2f-108">Unity [has also wrapped these windows APIs](../unity/locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="21e2f-109">Información de cámara de dispositivo</span><span class="sxs-lookup"><span data-stu-id="21e2f-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="21e2f-110">HoloLens (primera generación)</span><span class="sxs-lookup"><span data-stu-id="21e2f-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="21e2f-111">Cámara de foto/vídeo (PV) de enfoque fijo con equilibrio de blanco automático, exposición automática y canalización de procesamiento de imágenes completas.</span><span class="sxs-lookup"><span data-stu-id="21e2f-111">Fixed focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="21e2f-112">El LED de privacidad en blanco para el mundo se iluminará siempre que la cámara esté activa</span><span class="sxs-lookup"><span data-stu-id="21e2f-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="21e2f-113">La cámara admite los siguientes modos (todos los modos tienen una relación de aspecto de 16:9) a 30, 24, 20, 15 y 5 FPS:</span><span class="sxs-lookup"><span data-stu-id="21e2f-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="21e2f-114">Vídeo</span><span class="sxs-lookup"><span data-stu-id="21e2f-114">Video</span></span>  |  <span data-ttu-id="21e2f-115">Vista previa</span><span class="sxs-lookup"><span data-stu-id="21e2f-115">Preview</span></span>  |  <span data-ttu-id="21e2f-116">¿</span><span class="sxs-lookup"><span data-stu-id="21e2f-116">Still</span></span>  |  <span data-ttu-id="21e2f-117">Campo horizontal de la vista (H-Field)</span><span class="sxs-lookup"><span data-stu-id="21e2f-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="21e2f-118">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="21e2f-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="21e2f-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-119">1280x720</span></span> |  <span data-ttu-id="21e2f-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-120">1280x720</span></span> |  <span data-ttu-id="21e2f-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-121">1280x720</span></span> |  <span data-ttu-id="21e2f-122">45deg</span><span class="sxs-lookup"><span data-stu-id="21e2f-122">45deg</span></span>  |  <span data-ttu-id="21e2f-123">(modo predeterminado con estabilización de vídeo)</span><span class="sxs-lookup"><span data-stu-id="21e2f-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="21e2f-124">N/D</span><span class="sxs-lookup"><span data-stu-id="21e2f-124">N/A</span></span> |  <span data-ttu-id="21e2f-125">N/D</span><span class="sxs-lookup"><span data-stu-id="21e2f-125">N/A</span></span> |  <span data-ttu-id="21e2f-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="21e2f-126">2048x1152</span></span> |  <span data-ttu-id="21e2f-127">67deg</span><span class="sxs-lookup"><span data-stu-id="21e2f-127">67deg</span></span> |  <span data-ttu-id="21e2f-128">Imagen fija de mayor resolución</span><span class="sxs-lookup"><span data-stu-id="21e2f-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="21e2f-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="21e2f-129">1408x792</span></span> |  <span data-ttu-id="21e2f-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="21e2f-130">1408x792</span></span> |  <span data-ttu-id="21e2f-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="21e2f-131">1408x792</span></span> |  <span data-ttu-id="21e2f-132">48deg</span><span class="sxs-lookup"><span data-stu-id="21e2f-132">48deg</span></span> |  <span data-ttu-id="21e2f-133">Resolución de sobrebarrido (relleno) antes de la estabilización de vídeo</span><span class="sxs-lookup"><span data-stu-id="21e2f-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="21e2f-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="21e2f-134">1344x756</span></span> |  <span data-ttu-id="21e2f-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="21e2f-135">1344x756</span></span> |  <span data-ttu-id="21e2f-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="21e2f-136">1344x756</span></span> |  <span data-ttu-id="21e2f-137">67deg</span><span class="sxs-lookup"><span data-stu-id="21e2f-137">67deg</span></span> |  <span data-ttu-id="21e2f-138">Modo de vídeo de hiperjuego grande con sobrebarrido</span><span class="sxs-lookup"><span data-stu-id="21e2f-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="21e2f-139">896x504</span><span class="sxs-lookup"><span data-stu-id="21e2f-139">896x504</span></span> |  <span data-ttu-id="21e2f-140">896x504</span><span class="sxs-lookup"><span data-stu-id="21e2f-140">896x504</span></span> |  <span data-ttu-id="21e2f-141">896x504</span><span class="sxs-lookup"><span data-stu-id="21e2f-141">896x504</span></span> |  <span data-ttu-id="21e2f-142">48deg</span><span class="sxs-lookup"><span data-stu-id="21e2f-142">48deg</span></span> |  <span data-ttu-id="21e2f-143">Modo de baja energía/baja resolución para las tareas de procesamiento de imágenes</span><span class="sxs-lookup"><span data-stu-id="21e2f-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="21e2f-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="21e2f-144">HoloLens 2</span></span>

* <span data-ttu-id="21e2f-145">Centrar automáticamente la cámara de foto/vídeo (PV) con el equilibrio de blancos automático, la exposición automática y la canalización de procesamiento de imágenes completas.</span><span class="sxs-lookup"><span data-stu-id="21e2f-145">Auto-focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="21e2f-146">El LED de privacidad en blanco orientado al mundo se iluminará cada vez que la cámara esté activa.</span><span class="sxs-lookup"><span data-stu-id="21e2f-146">White Privacy LED facing the world will illuminate whenever the camera is active.</span></span>
* <span data-ttu-id="21e2f-147">HoloLens 2 admite distintos perfiles de cámara.</span><span class="sxs-lookup"><span data-stu-id="21e2f-147">HoloLens 2 supports different camera profiles.</span></span> <span data-ttu-id="21e2f-148">Obtenga información acerca de cómo [detectar y seleccionar funcionalidades de la cámara](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span><span class="sxs-lookup"><span data-stu-id="21e2f-148">Learn how to [discover and select camera capabilities](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span></span>
* <span data-ttu-id="21e2f-149">La cámara admite los siguientes perfiles y resoluciones (todos los modos de vídeo tienen una relación de aspecto de 16:9):</span><span class="sxs-lookup"><span data-stu-id="21e2f-149">The camera supports the following profiles and resolutions (all video modes are 16:9 aspect ratio):</span></span>
  
  | <span data-ttu-id="21e2f-150">Perfil</span><span class="sxs-lookup"><span data-stu-id="21e2f-150">Profile</span></span>                                         | <span data-ttu-id="21e2f-151">Vídeo</span><span class="sxs-lookup"><span data-stu-id="21e2f-151">Video</span></span>     | <span data-ttu-id="21e2f-152">Vista previa</span><span class="sxs-lookup"><span data-stu-id="21e2f-152">Preview</span></span>   | <span data-ttu-id="21e2f-153">¿</span><span class="sxs-lookup"><span data-stu-id="21e2f-153">Still</span></span>     | <span data-ttu-id="21e2f-154">Velocidades de fotogramas</span><span class="sxs-lookup"><span data-stu-id="21e2f-154">Frame rates</span></span> | <span data-ttu-id="21e2f-155">Campo horizontal de la vista (H-Field)</span><span class="sxs-lookup"><span data-stu-id="21e2f-155">Horizontal Field of View (H-FOV)</span></span> | <span data-ttu-id="21e2f-156">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="21e2f-156">Suggested usage</span></span>                             |
  |-------------------------------------------------|-----------|-----------|-----------|-------------|----------------------------------|---------------------------------------------|
  | <span data-ttu-id="21e2f-157">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="21e2f-157">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="21e2f-158">2272x1278</span><span class="sxs-lookup"><span data-stu-id="21e2f-158">2272x1278</span></span> | <span data-ttu-id="21e2f-159">2272x1278</span><span class="sxs-lookup"><span data-stu-id="21e2f-159">2272x1278</span></span> |           | <span data-ttu-id="21e2f-160">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-160">15,30</span></span>       | <span data-ttu-id="21e2f-161">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-161">64.69</span></span>                            | <span data-ttu-id="21e2f-162">Grabación de vídeo de alta calidad</span><span class="sxs-lookup"><span data-stu-id="21e2f-162">High quality video recording</span></span>                |
  | <span data-ttu-id="21e2f-163">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="21e2f-163">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="21e2f-164">896x504</span><span class="sxs-lookup"><span data-stu-id="21e2f-164">896x504</span></span>   | <span data-ttu-id="21e2f-165">896x504</span><span class="sxs-lookup"><span data-stu-id="21e2f-165">896x504</span></span>   |           | <span data-ttu-id="21e2f-166">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-166">15,30</span></span>       | <span data-ttu-id="21e2f-167">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-167">64.69</span></span>                            | <span data-ttu-id="21e2f-168">Flujo de vista previa para la captura de fotografías de alta calidad</span><span class="sxs-lookup"><span data-stu-id="21e2f-168">Preview stream for high quality photo capture</span></span> |
  | <span data-ttu-id="21e2f-169">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="21e2f-169">Legacy,0  BalancedVideoAndPhoto,100</span></span>             |           |           | <span data-ttu-id="21e2f-170">3904x2196</span><span class="sxs-lookup"><span data-stu-id="21e2f-170">3904x2196</span></span> |             | <span data-ttu-id="21e2f-171">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-171">64.69</span></span>                            | <span data-ttu-id="21e2f-172">Captura de fotografías de alta calidad</span><span class="sxs-lookup"><span data-stu-id="21e2f-172">High quality photo capture</span></span>                  |
  | <span data-ttu-id="21e2f-173">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-173">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="21e2f-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-174">1952x1100</span></span> | <span data-ttu-id="21e2f-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-175">1952x1100</span></span> | <span data-ttu-id="21e2f-176">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-176">1952x1100</span></span> | <span data-ttu-id="21e2f-177">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-177">15,30</span></span>       | <span data-ttu-id="21e2f-178">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-178">64.69</span></span>                            | <span data-ttu-id="21e2f-179">Escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-179">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="21e2f-180">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-180">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="21e2f-181">1504x846</span><span class="sxs-lookup"><span data-stu-id="21e2f-181">1504x846</span></span>  | <span data-ttu-id="21e2f-182">1504x846</span><span class="sxs-lookup"><span data-stu-id="21e2f-182">1504x846</span></span>  |           | <span data-ttu-id="21e2f-183">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-183">15,30</span></span>       | <span data-ttu-id="21e2f-184">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-184">64.69</span></span>                            | <span data-ttu-id="21e2f-185">Escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-185">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="21e2f-186">Videoconferencia, 100</span><span class="sxs-lookup"><span data-stu-id="21e2f-186">VideoConferencing,100</span></span>                           | <span data-ttu-id="21e2f-187">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-187">1952x1100</span></span> | <span data-ttu-id="21e2f-188">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-188">1952x1100</span></span> | <span data-ttu-id="21e2f-189">1952x1100</span><span class="sxs-lookup"><span data-stu-id="21e2f-189">1952x1100</span></span> | <span data-ttu-id="21e2f-190">15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="21e2f-190">15,30,60</span></span>    | <span data-ttu-id="21e2f-191">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-191">64.69</span></span>                            | <span data-ttu-id="21e2f-192">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-192">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-193">Videoconferencia, 100</span><span class="sxs-lookup"><span data-stu-id="21e2f-193">Videoconferencing,100</span></span>                           | <span data-ttu-id="21e2f-194">1504x846</span><span class="sxs-lookup"><span data-stu-id="21e2f-194">1504x846</span></span>  | <span data-ttu-id="21e2f-195">1504x846</span><span class="sxs-lookup"><span data-stu-id="21e2f-195">1504x846</span></span>  |           | <span data-ttu-id="21e2f-196">5, 15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="21e2f-196">5,15,30,60</span></span>  | <span data-ttu-id="21e2f-197">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-197">64.69</span></span>                            | <span data-ttu-id="21e2f-198">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-198">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-199">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-199">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-200">x</span><span class="sxs-lookup"><span data-stu-id="21e2f-200">1920x1080</span></span> | <span data-ttu-id="21e2f-201">x</span><span class="sxs-lookup"><span data-stu-id="21e2f-201">1920x1080</span></span> | <span data-ttu-id="21e2f-202">x</span><span class="sxs-lookup"><span data-stu-id="21e2f-202">1920x1080</span></span> | <span data-ttu-id="21e2f-203">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-203">15,30</span></span>       | <span data-ttu-id="21e2f-204">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-204">64.69</span></span>                            | <span data-ttu-id="21e2f-205">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-205">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-206">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-206">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-207">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-207">1280x720</span></span>  | <span data-ttu-id="21e2f-208">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-208">1280x720</span></span>  | <span data-ttu-id="21e2f-209">1280x720</span><span class="sxs-lookup"><span data-stu-id="21e2f-209">1280x720</span></span>  | <span data-ttu-id="21e2f-210">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-210">15,30</span></span>       | <span data-ttu-id="21e2f-211">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-211">64.69</span></span>                            | <span data-ttu-id="21e2f-212">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-212">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-213">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-213">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-214">1128x636</span><span class="sxs-lookup"><span data-stu-id="21e2f-214">1128x636</span></span>  |           |           | <span data-ttu-id="21e2f-215">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-215">15,30</span></span>       | <span data-ttu-id="21e2f-216">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-216">64.69</span></span>                            | <span data-ttu-id="21e2f-217">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-217">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-218">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-218">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-219">960 x 540</span><span class="sxs-lookup"><span data-stu-id="21e2f-219">960x540</span></span>   |           |           | <span data-ttu-id="21e2f-220">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-220">15,30</span></span>       | <span data-ttu-id="21e2f-221">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-221">64.69</span></span>                            | <span data-ttu-id="21e2f-222">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-222">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-223">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-223">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-224">760x428</span><span class="sxs-lookup"><span data-stu-id="21e2f-224">760x428</span></span>   |           |           | <span data-ttu-id="21e2f-225">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-225">15,30</span></span>       | <span data-ttu-id="21e2f-226">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-226">64.69</span></span>                            | <span data-ttu-id="21e2f-227">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-227">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-228">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-228">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-229">640 x 360</span><span class="sxs-lookup"><span data-stu-id="21e2f-229">640x360</span></span>   |           |           | <span data-ttu-id="21e2f-230">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-230">15,30</span></span>       | <span data-ttu-id="21e2f-231">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-231">64.69</span></span>                            | <span data-ttu-id="21e2f-232">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-232">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-233">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-233">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-234">500x282</span><span class="sxs-lookup"><span data-stu-id="21e2f-234">500x282</span></span>   |           |           | <span data-ttu-id="21e2f-235">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-235">15,30</span></span>       | <span data-ttu-id="21e2f-236">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-236">64.69</span></span>                            | <span data-ttu-id="21e2f-237">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-237">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="21e2f-238">Videoconferencia, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="21e2f-238">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="21e2f-239">424x240</span><span class="sxs-lookup"><span data-stu-id="21e2f-239">424x240</span></span>   |           |           | <span data-ttu-id="21e2f-240">15, 30</span><span class="sxs-lookup"><span data-stu-id="21e2f-240">15,30</span></span>       | <span data-ttu-id="21e2f-241">64,69</span><span class="sxs-lookup"><span data-stu-id="21e2f-241">64.69</span></span>                            | <span data-ttu-id="21e2f-242">Videoconferencia, escenarios de larga duración</span><span class="sxs-lookup"><span data-stu-id="21e2f-242">Video conferencing, long duration scenarios</span></span> |

> [!NOTE]
> <span data-ttu-id="21e2f-243">Los clientes pueden aprovechar la [captura de realidad mixta](../../mixed-reality-capture.md) para tomar vídeos o fotos de la aplicación, que incluyen hologramas y estabilización de vídeo.</span><span class="sxs-lookup"><span data-stu-id="21e2f-243">Customers can leverage [mixed reality capture](../../mixed-reality-capture.md) to take videos or photos of your app, which include holograms and video stabilization.</span></span>
>
><span data-ttu-id="21e2f-244">Como desarrollador, existen consideraciones que debe tener en cuenta a la hora de crear la aplicación si quiere que se vea lo mejor posible cuando un cliente captura contenido.</span><span class="sxs-lookup"><span data-stu-id="21e2f-244">As a developer, there are considerations you should take into account when creating your app if you want it to look as good as possible when a customer captures content.</span></span> <span data-ttu-id="21e2f-245">También puede habilitar (y personalizar) la captura de realidad mixta desde directamente dentro de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="21e2f-245">You can also enable (and customize) mixed reality capture from directly within your app.</span></span> <span data-ttu-id="21e2f-246">Obtenga más información en [captura de realidad mixta para desarrolladores](mixed-reality-capture-for-developers.md).</span><span class="sxs-lookup"><span data-stu-id="21e2f-246">Learn more at [mixed reality capture for developers](mixed-reality-capture-for-developers.md).</span></span>

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="21e2f-247">Localizar la cámara del dispositivo en el mundo</span><span class="sxs-lookup"><span data-stu-id="21e2f-247">Locating the Device Camera in the World</span></span>

<span data-ttu-id="21e2f-248">Cuando HoloLens toma fotos y vídeos, los fotogramas capturados incluyen la ubicación de la cámara en el mundo, así como el modelo de lente de la cámara.</span><span class="sxs-lookup"><span data-stu-id="21e2f-248">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="21e2f-249">Esto permite a las aplicaciones tener en cuenta la posición de la cámara en el mundo real para escenarios de creación de imágenes mejorados.</span><span class="sxs-lookup"><span data-stu-id="21e2f-249">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="21e2f-250">Los desarrolladores pueden hacer un desarrollo creativo de sus propios escenarios mediante su procesamiento de imágenes favorito o bibliotecas personalizadas de equipos.</span><span class="sxs-lookup"><span data-stu-id="21e2f-250">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="21e2f-251">La "cámara" en otra parte de la documentación de HoloLens puede hacer referencia a la "cámara de juego virtual" (el frustum en el que se representa la aplicación).</span><span class="sxs-lookup"><span data-stu-id="21e2f-251">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="21e2f-252">A menos que se indique lo contrario, "Camera" se refiere a la cámara de color RGB del mundo real.</span><span class="sxs-lookup"><span data-stu-id="21e2f-252">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

### <a name="using-unity"></a><span data-ttu-id="21e2f-253">Con Unity</span><span class="sxs-lookup"><span data-stu-id="21e2f-253">Using Unity</span></span>

<span data-ttu-id="21e2f-254">Para ir de "CameraIntrinsics" y "CameraCoordinateSystem" al sistema de coordenadas del mundo o de la aplicación, siga las instrucciones del artículo sobre la [cámara localizable en Unity](../unity/locatable-camera-in-unity.md) .</span><span class="sxs-lookup"><span data-stu-id="21e2f-254">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, follow the instructions in the [Locatable camera in Unity](../unity/locatable-camera-in-unity.md) article.</span></span>  <span data-ttu-id="21e2f-255">La clase PhotoCaptureFrame proporciona automáticamente CameraToWorldMatrix, por lo que no es necesario preocuparse por las transformaciones CameraCoordinateSystem que se describen a continuación.</span><span class="sxs-lookup"><span data-stu-id="21e2f-255">CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class, and so you don't need to worry about the CameraCoordinateSystem transforms discussed below.</span></span>

### <a name="using-mediaframereference"></a><span data-ttu-id="21e2f-256">Usar MediaFrameReference</span><span class="sxs-lookup"><span data-stu-id="21e2f-256">Using MediaFrameReference</span></span>

<span data-ttu-id="21e2f-257">Estas instrucciones se aplican si usa la clase [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) para leer fotogramas de imagen de la cámara.</span><span class="sxs-lookup"><span data-stu-id="21e2f-257">These instructions apply if you are using the [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) class to read image frames from the camera.</span></span>

<span data-ttu-id="21e2f-258">Cada fotograma de imagen (ya sea fotográfico o vídeo) incluye una [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) raíz en la cámara en el momento de la captura, a la que se puede acceder mediante la propiedad [coordenadas](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) de su [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="21e2f-258">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture, which can be accessed using the [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="21e2f-259">Además, cada fotograma contiene una descripción del modelo de lente de la cámara, que puede encontrarse en la propiedad [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) .</span><span class="sxs-lookup"><span data-stu-id="21e2f-259">In addition, each frame contains a description of the camera lens model, which can be found in the [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="21e2f-260">Juntas, estas transformaciones definen para cada píxel un rayo en un espacio 3D que representa la ruta de acceso tomada por las fotografías que han producido el píxel.</span><span class="sxs-lookup"><span data-stu-id="21e2f-260">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="21e2f-261">Estos rayos pueden estar relacionados con otro contenido de la aplicación mediante la obtención de la transformación del sistema de coordenadas del marco a algún otro sistema de coordenadas (por ejemplo, desde un [marco estacionario de referencia](../../design/coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="21e2f-261">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](../../design/coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="21e2f-262">En Resumen, cada fotograma de imagen proporciona lo siguiente:</span><span class="sxs-lookup"><span data-stu-id="21e2f-262">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="21e2f-263">Datos de píxeles (en formato RGB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="21e2f-263">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="21e2f-264">Un [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) de la ubicación de la captura</span><span class="sxs-lookup"><span data-stu-id="21e2f-264">A [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="21e2f-265">Una clase [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) que contiene el modo de lente de la cámara</span><span class="sxs-lookup"><span data-stu-id="21e2f-265">A [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

<span data-ttu-id="21e2f-266">En el [ejemplo HolographicFaceTracking](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) se muestra la forma bastante sencilla de consultar la transformación entre el sistema de coordenadas de la cámara y sus propios sistemas de coordenadas de aplicación.</span><span class="sxs-lookup"><span data-stu-id="21e2f-266">The [HolographicFaceTracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate systems.</span></span>

### <a name="using-media-foundation"></a><span data-ttu-id="21e2f-267">Usar Media Foundation</span><span class="sxs-lookup"><span data-stu-id="21e2f-267">Using Media Foundation</span></span>

<span data-ttu-id="21e2f-268">Si usa Media Foundation directamente para leer fotogramas de imagen de la cámara, puede usar el [atributo MFSampleExtension_CameraExtrinsics](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) de cada fotograma y el [atributo MFSampleExtension_PinholeCameraIntrinsics](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) para buscar fotogramas de cámara relativos a los demás sistemas de coordenadas de la aplicación, tal como se muestra en este código de ejemplo:</span><span class="sxs-lookup"><span data-stu-id="21e2f-268">If you are using Media Foundation directly to read image frames from the camera, you can use each frame's [MFSampleExtension_CameraExtrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) and [MFSampleExtension_PinholeCameraIntrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) to locate camera frames relative to your application's other coordinate systems, as shown in this sample code:</span></span>

```cpp
#include <winrt/windows.perception.spatial.preview.h>
#include <mfapi.h>
#include <mfidl.h>
 
using namespace winrt::Windows::Foundation;
using namespace winrt::Windows::Foundation::Numerics;
using namespace winrt::Windows::Perception;
using namespace winrt::Windows::Perception::Spatial;
using namespace winrt::Windows::Perception::Spatial::Preview;
 
class CameraFrameLocator
{
public:
    struct CameraFrameLocation
    {
        SpatialCoordinateSystem CoordinateSystem;
        float4x4 CameraViewToCoordinateSytemTransform;
        MFPinholeCameraIntrinsics Intrinsics;
    };
 
    std::optional<CameraFrameLocation> TryLocateCameraFrame(IMFSample* pSample)
    {
        MFCameraExtrinsics cameraExtrinsics;
        MFPinholeCameraIntrinsics cameraIntrinsics;
        UINT32 sizeCameraExtrinsics = 0;
        UINT32 sizeCameraIntrinsics = 0;
        UINT64 sampleTimeHns = 0;
 
        // query sample for calibration and validate
        if (FAILED(pSample->GetUINT64(MFSampleExtension_DeviceTimestamp, &sampleTimeHns)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_CameraExtrinsics, (UINT8*)& cameraExtrinsics, sizeof(cameraExtrinsics), &sizeCameraExtrinsics)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_PinholeCameraIntrinsics, (UINT8*)& cameraIntrinsics, sizeof(cameraIntrinsics), &sizeCameraIntrinsics)) ||
            (sizeCameraExtrinsics != sizeof(cameraExtrinsics)) ||
            (sizeCameraIntrinsics != sizeof(cameraIntrinsics)) ||
            (cameraExtrinsics.TransformCount == 0))
        {
            return std::nullopt;
        }
 
        // compute extrinsic transform
        const auto& calibratedTransform = cameraExtrinsics.CalibratedTransforms[0];
        const GUID& dynamicNodeId = calibratedTransform.CalibrationId;
        const float4x4 cameraToDynamicNode =
            make_float4x4_from_quaternion(quaternion{ calibratedTransform.Orientation.x, calibratedTransform.Orientation.y, calibratedTransform.Orientation.z, calibratedTransform.Orientation.w }) *
            make_float4x4_translation(calibratedTransform.Position.x, calibratedTransform.Position.y, calibratedTransform.Position.z);
 
        // update locator cache for dynamic node
        if (dynamicNodeId != m_currentDynamicNodeId || !m_locator)
        {
            m_locator = SpatialGraphInteropPreview::CreateLocatorForNode(dynamicNodeId);
            if (!m_locator)
            {
                return std::nullopt;
            }
 
            m_frameOfReference = m_locator.CreateAttachedFrameOfReferenceAtCurrentHeading();
            m_currentDynamicNodeId = dynamicNodeId;
        }
 
        // locate dynamic node
        auto timestamp = PerceptionTimestampHelper::FromSystemRelativeTargetTime(TimeSpan{ sampleTimeHns });
        auto coordinateSystem = m_frameOfReference.GetStationaryCoordinateSystemAtTimestamp(timestamp);
        auto location = m_locator.TryLocateAtTimestamp(timestamp, coordinateSystem);
        if (!location)
        {
            return std::nullopt;
        }
 
        const float4x4 dynamicNodeToCoordinateSystem = make_float4x4_from_quaternion(location.Orientation()) * make_float4x4_translation(location.Position());
 
        return CameraFrameLocation{ coordinateSystem, cameraToDynamicNode * dynamicNodeToCoordinateSystem, cameraIntrinsics };
    }

private:
    GUID m_currentDynamicNodeId{ GUID_NULL };
    SpatialLocator m_locator{ nullptr };
    SpatialLocatorAttachedFrameOfReference m_frameOfReference{ nullptr };
};
```

### <a name="distortion-error"></a><span data-ttu-id="21e2f-269">Error de distorsión</span><span class="sxs-lookup"><span data-stu-id="21e2f-269">Distortion Error</span></span>

<span data-ttu-id="21e2f-270">En HoloLens, los flujos de vídeo y de imagen fija no se distorsionan en la canalización de procesamiento de imágenes del sistema antes de que los fotogramas estén disponibles para la aplicación (la secuencia de vista previa contiene los fotogramas distorsionados originales).</span><span class="sxs-lookup"><span data-stu-id="21e2f-270">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="21e2f-271">Dado que solo están disponibles los CameraIntrinsics, las aplicaciones deben suponer que los fotogramas de imagen representan una cámara pinhole perfecta.</span><span class="sxs-lookup"><span data-stu-id="21e2f-271">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera.</span></span>

<span data-ttu-id="21e2f-272">En HoloLens (primera generación), la función de no distorsión del procesador de imágenes todavía puede dejar un error de hasta 10 píxeles al usar CameraIntrinsics en los metadatos del marco.</span><span class="sxs-lookup"><span data-stu-id="21e2f-272">On HoloLens (first-generation), the undistortion function in the image processor may still leave an error of up to 10 pixels when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="21e2f-273">En muchos casos de uso, este error no es importante, pero si se alinean los hologramas con los pósteres o marcadores reales, por ejemplo, y observa una <desplazamiento de 10px (aproximadamente 11mm para los hologramas situados a dos metros de distancia), este error de distorsión podría ser la causa.</span><span class="sxs-lookup"><span data-stu-id="21e2f-273">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away), this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="21e2f-274">Escenarios de uso de cámara localizables</span><span class="sxs-lookup"><span data-stu-id="21e2f-274">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="21e2f-275">Mostrar una foto o un vídeo en el mundo en el que se capturó</span><span class="sxs-lookup"><span data-stu-id="21e2f-275">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="21e2f-276">Los fotogramas de la cámara del dispositivo tienen una transformación "cámara a mundo", que se puede usar para mostrar exactamente dónde estaba el dispositivo cuando se tomó la imagen.</span><span class="sxs-lookup"><span data-stu-id="21e2f-276">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="21e2f-277">Por ejemplo, podría colocar un pequeño icono de Holographic en esta ubicación (CameraToWorld. MultiplyPoint (Vector3. Zero)) e incluso dibujar una pequeña flecha en la dirección en la que se encontraba la cámara (CameraToWorld. MultiplyVector (Vector3. forward)).</span><span class="sxs-lookup"><span data-stu-id="21e2f-277">For example, you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="21e2f-278">Seguimiento de etiqueta/patrón/póster/objeto</span><span class="sxs-lookup"><span data-stu-id="21e2f-278">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="21e2f-279">Muchas aplicaciones de realidad mixta usan una imagen reconocible o un patrón visual para crear un punto de seguimiento en el espacio.</span><span class="sxs-lookup"><span data-stu-id="21e2f-279">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="21e2f-280">A continuación, se usa para representar objetos relativos a ese punto o crear una ubicación conocida.</span><span class="sxs-lookup"><span data-stu-id="21e2f-280">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="21e2f-281">Algunos usos de HoloLens incluyen la búsqueda de un objeto del mundo real etiquetado con fiducials (por ejemplo, un monitor de TV con un código QR), la colocación de hologramas en fiducials y el emparejamiento visual de los dispositivos que no sean de HoloLens, como tabletas que se han configurado para comunicarse con HoloLens a través de Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="21e2f-281">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="21e2f-282">Para reconocer un patrón visual y, a continuación, colocar ese objeto en el espacio del mundo de las aplicaciones, necesitará algunas cosas:</span><span class="sxs-lookup"><span data-stu-id="21e2f-282">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="21e2f-283">Un kit de herramientas de reconocimiento de patrones de imagen, como código QR, etiquetas AR, buscador de caras, rastreadores de círculos, OCR, etc.</span><span class="sxs-lookup"><span data-stu-id="21e2f-283">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="21e2f-284">Recopilar fotogramas de imagen en tiempo de ejecución y pasarlos a la capa de reconocimiento</span><span class="sxs-lookup"><span data-stu-id="21e2f-284">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="21e2f-285">Vuelva a proyectar las ubicaciones de las imágenes en las posiciones mundiales o en los rayos más probables.</span><span class="sxs-lookup"><span data-stu-id="21e2f-285">Unproject their image locations back into world positions, or likely world rays.</span></span> 
4. <span data-ttu-id="21e2f-286">Coloque los modelos virtuales en estas ubicaciones mundiales</span><span class="sxs-lookup"><span data-stu-id="21e2f-286">Position your virtual models over these world locations</span></span>

<span data-ttu-id="21e2f-287">Algunos vínculos de procesamiento de imágenes importantes:</span><span class="sxs-lookup"><span data-stu-id="21e2f-287">Some important image processing links:</span></span>
* [<span data-ttu-id="21e2f-288">OpenCV</span><span class="sxs-lookup"><span data-stu-id="21e2f-288">OpenCV</span></span>](https://opencv.org/)
* [<span data-ttu-id="21e2f-289">Etiquetas QR</span><span class="sxs-lookup"><span data-stu-id="21e2f-289">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="21e2f-290">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="21e2f-290">FaceSDK</span></span>](https://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="21e2f-291">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="21e2f-291">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="21e2f-292">Mantener una velocidad de fotogramas de aplicación interactiva es fundamental, especialmente cuando se trabaja con algoritmos de reconocimiento de imágenes de ejecución prolongada.</span><span class="sxs-lookup"><span data-stu-id="21e2f-292">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="21e2f-293">Por esta razón, normalmente usamos el patrón siguiente:</span><span class="sxs-lookup"><span data-stu-id="21e2f-293">For this reason, we commonly use the following pattern:</span></span>
1. <span data-ttu-id="21e2f-294">Subproceso principal: administra el objeto de cámara</span><span class="sxs-lookup"><span data-stu-id="21e2f-294">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="21e2f-295">Subproceso principal: solicita nuevos marcos (Async)</span><span class="sxs-lookup"><span data-stu-id="21e2f-295">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="21e2f-296">Subproceso principal: pasar nuevos marcos al subproceso de seguimiento</span><span class="sxs-lookup"><span data-stu-id="21e2f-296">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="21e2f-297">Subproceso de seguimiento: procesa la imagen para recopilar puntos clave</span><span class="sxs-lookup"><span data-stu-id="21e2f-297">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="21e2f-298">Subproceso principal: mueve el modelo virtual para que coincida con los puntos clave encontrados</span><span class="sxs-lookup"><span data-stu-id="21e2f-298">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="21e2f-299">Subproceso principal: repetir en el paso 2</span><span class="sxs-lookup"><span data-stu-id="21e2f-299">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="21e2f-300">Algunos sistemas de marcadores de imagen solo proporcionan una ubicación de un solo píxel (otros proporcionan la transformación completa en cuyo caso no se necesitará esta sección), lo que equivale a un rayo de ubicaciones posibles.</span><span class="sxs-lookup"><span data-stu-id="21e2f-300">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="21e2f-301">Para llegar a una sola ubicación 3D, podemos aprovechar varios rayos y buscar el resultado final por su intersección aproximada.</span><span class="sxs-lookup"><span data-stu-id="21e2f-301">To get to a single 3d location, we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="21e2f-302">Para ello, necesitará lo siguiente:</span><span class="sxs-lookup"><span data-stu-id="21e2f-302">To do this, you'll need to:</span></span>
1. <span data-ttu-id="21e2f-303">Obtener un bucle que va a recopilar varias imágenes de la cámara</span><span class="sxs-lookup"><span data-stu-id="21e2f-303">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="21e2f-304">Busque los puntos de características asociados y sus rayos mundiales</span><span class="sxs-lookup"><span data-stu-id="21e2f-304">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="21e2f-305">Si tiene un diccionario de características, cada una con varios rayos de mundo, puede usar el código siguiente para resolver la intersección de esos rayos:</span><span class="sxs-lookup"><span data-stu-id="21e2f-305">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="21e2f-306">Dadas dos o más ubicaciones de etiquetas de las que se ha realizado un seguimiento, puede colocar una escena modelada para ajustarse al escenario actual del usuario.</span><span class="sxs-lookup"><span data-stu-id="21e2f-306">Given two or more tracked tag locations, you can position a modelled scene to fit the user's current scenario.</span></span> <span data-ttu-id="21e2f-307">Si no puede asumir la gravedad, necesitará tres ubicaciones de etiquetas.</span><span class="sxs-lookup"><span data-stu-id="21e2f-307">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="21e2f-308">En muchos casos, usamos una combinación de colores simple en la que los esferas blancas representan ubicaciones de etiquetas de las que se realiza un seguimiento en tiempo real y las esferas azules representan ubicaciones de etiquetas modeladas.</span><span class="sxs-lookup"><span data-stu-id="21e2f-308">In many cases, we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations.</span></span> <span data-ttu-id="21e2f-309">Esto permite al usuario medir visualmente la calidad de la alineación.</span><span class="sxs-lookup"><span data-stu-id="21e2f-309">This allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="21e2f-310">Damos por sentado la siguiente configuración en todas las aplicaciones:</span><span class="sxs-lookup"><span data-stu-id="21e2f-310">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="21e2f-311">Dos o más ubicaciones de etiquetas modeladas</span><span class="sxs-lookup"><span data-stu-id="21e2f-311">Two or more modelled tag locations</span></span>
* <span data-ttu-id="21e2f-312">Un "espacio de calibración" que en la escena es el elemento primario de las etiquetas.</span><span class="sxs-lookup"><span data-stu-id="21e2f-312">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="21e2f-313">Identificador de la característica de cámara</span><span class="sxs-lookup"><span data-stu-id="21e2f-313">Camera feature identifier</span></span>
* <span data-ttu-id="21e2f-314">Comportamiento que mueve el espacio de calibración para alinear las etiquetas modeladas con las etiquetas en tiempo real (tenemos cuidado de mover el espacio primario, no los propios marcadores modelados, ya que otras conexiones son posiciones relativas a ellos).</span><span class="sxs-lookup"><span data-stu-id="21e2f-314">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="21e2f-315">Realizar un seguimiento o identificar objetos o caras del mundo real con LEDs u otras bibliotecas de reconocedores</span><span class="sxs-lookup"><span data-stu-id="21e2f-315">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="21e2f-316">Ejemplos:</span><span class="sxs-lookup"><span data-stu-id="21e2f-316">Examples:</span></span>
* <span data-ttu-id="21e2f-317">Robots industriales con LED (o códigos QR para objetos móviles más lentos)</span><span class="sxs-lookup"><span data-stu-id="21e2f-317">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="21e2f-318">Identificar y reconocer objetos en el salón</span><span class="sxs-lookup"><span data-stu-id="21e2f-318">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="21e2f-319">Identifique y reconozca a personas de la habitación (por ejemplo, coloque las tarjetas de contacto holográfica en caras)</span><span class="sxs-lookup"><span data-stu-id="21e2f-319">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="21e2f-320">Consulte también</span><span class="sxs-lookup"><span data-stu-id="21e2f-320">See also</span></span>
* [<span data-ttu-id="21e2f-321">Ejemplo de cámara localizable</span><span class="sxs-lookup"><span data-stu-id="21e2f-321">Locatable camera sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
* [<span data-ttu-id="21e2f-322">Cámara localizable en Unity</span><span class="sxs-lookup"><span data-stu-id="21e2f-322">Locatable camera in Unity</span></span>](../unity/locatable-camera-in-unity.md)
* [<span data-ttu-id="21e2f-323">Captura de realidad mixta</span><span class="sxs-lookup"><span data-stu-id="21e2f-323">Mixed reality capture</span></span>](../../mixed-reality-capture.md)
* [<span data-ttu-id="21e2f-324">Captura de realidad mixta para desarrolladores</span><span class="sxs-lookup"><span data-stu-id="21e2f-324">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="21e2f-325">Introducción a la captura multimedia</span><span class="sxs-lookup"><span data-stu-id="21e2f-325">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="21e2f-326">Ejemplo de seguimiento de caras holográficas</span><span class="sxs-lookup"><span data-stu-id="21e2f-326">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
