---
title: Manos y controladores de movimiento en DirectX
description: Guía del desarrollador para usar el seguimiento de mano y los controladores de movimiento en aplicaciones DirectX nativas.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 08/04/2020
ms.topic: article
keywords: manos, controladores de movimiento, DirectX, entrada, hologramas, auriculares de realidad mixta, auriculares de realidad mixta de Windows, auriculares de realidad virtual
ms.openlocfilehash: 3dcf3767a537ccc64cb06c6f44d765425a5578b9
ms.sourcegitcommit: dd13a32a5bb90bd53eeeea8214cd5384d7b9ef76
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 11/17/2020
ms.locfileid: "94678064"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="a1c7f-104">Manos y controladores de movimiento en DirectX</span><span class="sxs-lookup"><span data-stu-id="a1c7f-104">Hands and motion controllers in DirectX</span></span>

> [!NOTE]
> <span data-ttu-id="a1c7f-105">Este artículo está relacionado con las API nativas de WinRT heredadas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-105">This article relates to the legacy WinRT native APIs.</span></span>  <span data-ttu-id="a1c7f-106">En el caso de los nuevos proyectos de aplicaciones nativas, se recomienda usar la **[API de OpenXR](openxr-getting-started.md)**.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-106">For new native app projects, we recommend using the **[OpenXR API](openxr-getting-started.md)**.</span></span>

<span data-ttu-id="a1c7f-107">En Windows Mixed Reality, la entrada de [controlador de movimiento](../../design/motion-controllers.md) y la mano se administra a través de las API de entrada espaciales, que se encuentran en el espacio de nombres [Windows. UI. Input. Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) .</span><span class="sxs-lookup"><span data-stu-id="a1c7f-107">In Windows Mixed Reality, both hand and [motion controller](../../design/motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="a1c7f-108">Esto le permite controlar fácilmente acciones comunes, como **selecciones** , de la misma manera en los controladores de manos y de movimiento.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-108">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="a1c7f-109">Introducción</span><span class="sxs-lookup"><span data-stu-id="a1c7f-109">Getting started</span></span>

<span data-ttu-id="a1c7f-110">Para tener acceso a la entrada espacial en Windows Mixed Reality, empiece con la interfaz SpatialInteractionManager.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-110">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="a1c7f-111">Puede tener acceso a esta interfaz mediante una llamada a  [SpatialInteractionManager:: GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), normalmente durante el inicio de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-111">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="a1c7f-112">El trabajo de SpatialInteractionManager es proporcionar acceso a [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), que representa un origen de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-112">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="a1c7f-113">Hay tres tipos de SpatialInteractionSources disponibles en el sistema.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-113">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="a1c7f-114">**Hand** representa la mano detectada de un usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-114">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="a1c7f-115">Los orígenes de mano ofrecen diferentes características basadas en el dispositivo, que abarcan desde gestos básicos de HoloLens hasta un seguimiento completo de la mano en HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-115">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="a1c7f-116">**Controller** representa un controlador de movimiento emparejado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-116">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="a1c7f-117">Los controladores de movimiento pueden ofrecer una variedad de funcionalidades.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-117">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="a1c7f-118">Por ejemplo: seleccione desencadenadores, botones de menú, botones de agarre, Touchpad y thumbsticks.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-118">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="a1c7f-119">**Voice** representa las palabras clave detectadas por el sistema de habla de voz del usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-119">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="a1c7f-120">Por ejemplo, este origen insertará una imprenta SELECT y Release siempre que el usuario diga "Select".</span><span class="sxs-lookup"><span data-stu-id="a1c7f-120">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="a1c7f-121">Los datos por fotograma para un origen se representan mediante la interfaz  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) .</span><span class="sxs-lookup"><span data-stu-id="a1c7f-121">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="a1c7f-122">Hay dos maneras diferentes de acceder a estos datos, en función de si desea usar un modelo basado en eventos o en el sondeo en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-122">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="a1c7f-123">Entrada controlada por eventos</span><span class="sxs-lookup"><span data-stu-id="a1c7f-123">Event-driven input</span></span>
<span data-ttu-id="a1c7f-124">SpatialInteractionManager proporciona varios eventos para los que puede escuchar la aplicación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-124">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="a1c7f-125">Algunos ejemplos son   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) y [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-125">A few examples include   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="a1c7f-126">Por ejemplo, el código siguiente enlaza un controlador de eventos denominado MyApp:: OnSourcePressed al evento SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-126">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="a1c7f-127">Esto permite que la aplicación detecte presiones en cualquier tipo de origen de interacción.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-127">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="a1c7f-128">Este evento presionado se envía a la aplicación de forma asincrónica, junto con el SpatialInteractionSourceState correspondiente en el momento en que se produjo el error.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-128">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="a1c7f-129">Es posible que la aplicación o el motor de juegos quiera realizar algún procesamiento de inmediato o que desee poner en cola los datos de eventos en la rutina de procesamiento de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-129">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="a1c7f-130">Esta es una función de controlador de eventos para el evento SourcePressed, que muestra cómo comprobar si se presionó el botón seleccionar.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-130">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="a1c7f-131">El código anterior solo comprueba la acción "Select", que corresponde a la acción primaria en el dispositivo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-131">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="a1c7f-132">Entre los ejemplos se incluye la realización de una AirTap en HoloLens o la extracción del desencadenador en un controlador de movimiento.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-132">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="a1c7f-133">Las presiones de "Select" representan la intención del usuario de activar el holograma al que están destinadas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-133">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="a1c7f-134">El evento SourcePressed se activará para varios botones y gestos diferentes, y puede inspeccionar otras propiedades en el SpatialInteractionSource para comprobar dichos casos.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-134">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="a1c7f-135">Entrada basada en sondeo</span><span class="sxs-lookup"><span data-stu-id="a1c7f-135">Polling-based input</span></span>
<span data-ttu-id="a1c7f-136">También puede usar SpatialInteractionManager para sondear el estado actual de la entrada de cada fotograma.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-136">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="a1c7f-137">Para ello, basta con llamar a [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) en cada fotograma.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-137">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="a1c7f-138">Esta función devuelve una matriz que contiene un [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) para cada [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)activo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-138">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="a1c7f-139">Esto significa que una para cada controlador de movimiento activo, uno para cada mano a la que se ha realizado un seguimiento y otro para la voz si se ha creado recientemente un comando "Select".</span><span class="sxs-lookup"><span data-stu-id="a1c7f-139">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="a1c7f-140">Después, puede inspeccionar las propiedades de cada SpatialInteractionSourceState para dirigir la entrada a la aplicación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-140">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="a1c7f-141">Este es un ejemplo de cómo buscar la acción "Select" mediante el método de sondeo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-141">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="a1c7f-142">Tenga en cuenta que la variable de *predicción* representa un objeto [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) , que se puede obtener a partir de [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-142">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="a1c7f-143">Cada SpatialInteractionSource tiene un identificador, que se puede usar para identificar nuevos orígenes y correlacionar los orígenes existentes entre fotogramas y fotogramas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-143">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="a1c7f-144">A las manos se les asigna un nuevo ID. cada vez que salen y entran en el hiperusuario, pero los identificadores de controlador siguen siendo estáticos mientras dure la sesión.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-144">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="a1c7f-145">Puede usar los eventos de SpatialInteractionManager, como [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) y [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), para reaccionar cuando las manos entran o salen de la vista del dispositivo, o cuando los controladores de movimiento se activan o desactivan o se emparejan o desemparejan.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-145">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="a1c7f-146">Supuestos previstos frente a supuestos históricos</span><span class="sxs-lookup"><span data-stu-id="a1c7f-146">Predicted vs. historical poses</span></span>
<span data-ttu-id="a1c7f-147">Tenga en cuenta que GetDetectedSourcesAtTimestamp tiene un parámetro timestamp.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-147">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="a1c7f-148">Esto le permite solicitar el estado y presentar datos que sean predecidos o históricos, lo que le permitirá poner en correlación las interacciones espaciales con otros orígenes de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-148">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="a1c7f-149">Por ejemplo, al representar la posición de la mano en el fotograma actual, puede pasar la marca de tiempo de predicción proporcionada por [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-149">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="a1c7f-150">Esto permite que el sistema avance y prediga la posición de la mano para que se alinee con la salida del fotograma representado, lo que minimiza la latencia percibida.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-150">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="a1c7f-151">Sin embargo, una pose de predicción de este tipo no produce un rayo apuntador ideal para el destino con un origen de interacción.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-151">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="a1c7f-152">Por ejemplo, cuando se presiona un botón de controlador de movimiento, puede tardar hasta 20 ms para que ese evento se propague a través de Bluetooth al sistema operativo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-152">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="a1c7f-153">Del mismo modo, después de que un usuario realice un gesto de mano, es posible que haya transcurrido un período de tiempo antes de que el sistema detecte el movimiento y la aplicación lo sondeará.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-153">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="a1c7f-154">En el momento en que la aplicación sondea un cambio de estado, el encabezado y la mano se usan para dirigirse realmente a esa interacción en el pasado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-154">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="a1c7f-155">Si tiene como destino el paso de la marca de tiempo de su HolographicFrame actual a GetDetectedSourcesAtTimestamp, la pose se predice en su lugar al rayo de destino en el momento en que se mostrará el fotograma, lo que podría ser superior a 20 MS en el futuro.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-155">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="a1c7f-156">Este planteamiento futuro es adecuado para *representar* el origen de la interacción, pero constituye un problema de tiempo para *dirigirse* a la interacción, ya que los destinatarios del usuario se produjeron en el pasado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-156">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="a1c7f-157">Afortunadamente, los eventos [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) y [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) proporcionan el [Estado](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) histórico asociado a cada evento de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-157">Fortunately, the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="a1c7f-158">Esto incluye directamente el encabezado histórico y las manos disponibles a través de [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), junto con una [marca](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) de tiempo histórica que puede pasar a otras API para correlacionar con este evento.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-158">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="a1c7f-159">Esto conduce a las siguientes prácticas recomendadas al representar y destinar a manos y controladores cada fotograma:</span><span class="sxs-lookup"><span data-stu-id="a1c7f-159">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="a1c7f-160">En cuanto a la **representación manual o del controlador** en cada fotograma, la aplicación debe **sondear** la suposición de **predicción de reenvío** de cada origen de interacción en el momento de Photon del fotograma actual.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-160">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="a1c7f-161">Puede sondear todos los orígenes de interacción llamando a [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) cada fotograma, pasando la marca de tiempo de predicción proporcionada por [HolographicFrame:: CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-161">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="a1c7f-162">En el caso de los **destinatarios** de la mano o del controlador, en una imprenta o en una versión, la aplicación debe controlar **los eventos** presionados o liberados, raycasting basándose **en el encabezado** o la pose de la mano del evento.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-162">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="a1c7f-163">Para obtener este rayo de destino, puede controlar el evento [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) o [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) , obtener la propiedad [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) de los argumentos de evento y, a continuación, llamar a su método [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) .</span><span class="sxs-lookup"><span data-stu-id="a1c7f-163">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="a1c7f-164">Propiedades de entrada entre dispositivos</span><span class="sxs-lookup"><span data-stu-id="a1c7f-164">Cross-device input properties</span></span>
<span data-ttu-id="a1c7f-165">La API de SpatialInteractionSource admite controladores y sistemas de seguimiento de mano con una amplia gama de funcionalidades.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-165">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="a1c7f-166">Una serie de estas funcionalidades son comunes entre los tipos de dispositivo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-166">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="a1c7f-167">Por ejemplo, el seguimiento de mano y los controladores de movimiento proporcionan una acción "Select" y una posición 3D.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-167">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="a1c7f-168">Siempre que sea posible, la API asigna estas funciones comunes a las mismas propiedades en el SpatialInteractionSource.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-168">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="a1c7f-169">Esto permite a las aplicaciones admitir más fácilmente una amplia gama de tipos de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-169">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="a1c7f-170">En la tabla siguiente se describen las propiedades que se admiten y cómo se comparan entre los tipos de entrada.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-170">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="a1c7f-171">Propiedad</span><span class="sxs-lookup"><span data-stu-id="a1c7f-171">Property</span></span> | <span data-ttu-id="a1c7f-172">Descripción</span><span class="sxs-lookup"><span data-stu-id="a1c7f-172">Description</span></span> | <span data-ttu-id="a1c7f-173">Gestos de HoloLens (primera generación)</span><span class="sxs-lookup"><span data-stu-id="a1c7f-173">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="a1c7f-174">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="a1c7f-174">Motion Controllers</span></span> | <span data-ttu-id="a1c7f-175">Manos articuladas</span><span class="sxs-lookup"><span data-stu-id="a1c7f-175">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="a1c7f-176">SpatialInteractionSource::**Handl**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-176">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="a1c7f-177">Mano derecha o izquierda/controlador.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-177">Right or left hand / controller.</span></span> | <span data-ttu-id="a1c7f-178">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-178">Not Supported</span></span> | <span data-ttu-id="a1c7f-179">Compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-179">Supported</span></span> | <span data-ttu-id="a1c7f-180">Compatible.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-180">Supported</span></span> |
| [<span data-ttu-id="a1c7f-181">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-181">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="a1c7f-182">Estado actual del botón principal.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-182">Current state of the primary button.</span></span> | <span data-ttu-id="a1c7f-183">TAP del aire</span><span class="sxs-lookup"><span data-stu-id="a1c7f-183">Air Tap</span></span> | <span data-ttu-id="a1c7f-184">Desencadenador</span><span class="sxs-lookup"><span data-stu-id="a1c7f-184">Trigger</span></span> | <span data-ttu-id="a1c7f-185">Pulsación aérea relajada (bajo contacto vertical)</span><span class="sxs-lookup"><span data-stu-id="a1c7f-185">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="a1c7f-186">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-186">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="a1c7f-187">Estado actual del botón de arrastre.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-187">Current state of the grab button.</span></span> | <span data-ttu-id="a1c7f-188">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-188">Not Supported</span></span> | <span data-ttu-id="a1c7f-189">Botón de arrastre</span><span class="sxs-lookup"><span data-stu-id="a1c7f-189">Grab button</span></span> | <span data-ttu-id="a1c7f-190">Alejar o cerrar mano</span><span class="sxs-lookup"><span data-stu-id="a1c7f-190">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="a1c7f-191">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-191">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="a1c7f-192">Estado actual del botón de menú.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-192">Current state of the menu button.</span></span>    | <span data-ttu-id="a1c7f-193">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-193">Not Supported</span></span> | <span data-ttu-id="a1c7f-194">Botón de menú</span><span class="sxs-lookup"><span data-stu-id="a1c7f-194">Menu Button</span></span> | <span data-ttu-id="a1c7f-195">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-195">Not Supported</span></span> |
| [<span data-ttu-id="a1c7f-196">SpatialInteractionSourceLocation::**Position**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-196">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="a1c7f-197">Ubicación XYZ de la mano o posición del puño en el controlador.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-197">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="a1c7f-198">Ubicación de Palm</span><span class="sxs-lookup"><span data-stu-id="a1c7f-198">Palm location</span></span> | <span data-ttu-id="a1c7f-199">Posición de la postura de control</span><span class="sxs-lookup"><span data-stu-id="a1c7f-199">Grip pose position</span></span> | <span data-ttu-id="a1c7f-200">Ubicación de Palm</span><span class="sxs-lookup"><span data-stu-id="a1c7f-200">Palm location</span></span> |
| [<span data-ttu-id="a1c7f-201">SpatialInteractionSourceLocation::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-201">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="a1c7f-202">Cuaternión que representa la orientación de la mano o del puño en el controlador.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-202">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="a1c7f-203">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-203">Not Supported</span></span> | <span data-ttu-id="a1c7f-204">Orientación de la pose de puño</span><span class="sxs-lookup"><span data-stu-id="a1c7f-204">Grip pose orientation</span></span> | <span data-ttu-id="a1c7f-205">Orientación de Palm</span><span class="sxs-lookup"><span data-stu-id="a1c7f-205">Palm orientation</span></span> |
| [<span data-ttu-id="a1c7f-206">SpatialPointerInteractionSourcePose::**Position**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-206">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="a1c7f-207">Origen del rayo señalador.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-207">Origin of the pointing ray.</span></span> | <span data-ttu-id="a1c7f-208">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-208">Not Supported</span></span> | <span data-ttu-id="a1c7f-209">Compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-209">Supported</span></span> | <span data-ttu-id="a1c7f-210">Compatible.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-210">Supported</span></span> |
| [<span data-ttu-id="a1c7f-211">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="a1c7f-211">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="a1c7f-212">Dirección del rayo señalador.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-212">Direction of the pointing ray.</span></span> | <span data-ttu-id="a1c7f-213">No compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-213">Not Supported</span></span> | <span data-ttu-id="a1c7f-214">Compatible</span><span class="sxs-lookup"><span data-stu-id="a1c7f-214">Supported</span></span> | <span data-ttu-id="a1c7f-215">Compatible.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-215">Supported</span></span> |

<span data-ttu-id="a1c7f-216">Algunas de las propiedades anteriores no están disponibles en todos los dispositivos y la API proporciona un medio para probar esto.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-216">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="a1c7f-217">Por ejemplo, puede inspeccionar la propiedad [SpatialInteractionSource:: IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) para determinar si el origen proporciona una acción de agarre.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-217">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="a1c7f-218">Replanteamiento de control frente a pose de puntero</span><span class="sxs-lookup"><span data-stu-id="a1c7f-218">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="a1c7f-219">Windows Mixed Reality admite controladores de movimiento en diversos factores de forma.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-219">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="a1c7f-220">También admite sistemas de seguimiento de mano articulados.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-220">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="a1c7f-221">Todos estos sistemas tienen relaciones diferentes entre la posición de la mano y la dirección de "avance" natural que las aplicaciones deben usar para señalar o representar objetos en la mano del usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-221">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="a1c7f-222">Para admitir todo esto, se proporcionan dos tipos de supuestos 3D para el seguimiento y los controladores de movimiento de la mano.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-222">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="a1c7f-223">La primera es la postura de control, que representa la posición del usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-223">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="a1c7f-224">La segunda es el representador que señala, que representa un rayo señalador que se origina desde la mano o el controlador del usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-224">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="a1c7f-225">Por lo tanto, si desea presentar **la mano del usuario** o **un objeto mantenido en la mano del usuario**, por ejemplo, un arma o un cañón, utilice la postura de control.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-225">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="a1c7f-226">Si desea Raycast del controlador o de la mano, por ejemplo, cuando el usuario **apunta a la interfaz** de usuario, use la pose de puntero.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-226">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="a1c7f-227">Puede tener acceso a la **pose de control** a través de [SpatialInteractionSourceState::P ropiedades:: TryGetLocation (...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Se define de la siguiente manera:</span><span class="sxs-lookup"><span data-stu-id="a1c7f-227">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="a1c7f-228">La **posición del puño**: Palm centroide cuando mantiene el controlador de forma natural, se ajusta hacia la izquierda o derecha para centrar la posición dentro del control.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-228">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="a1c7f-229">**Eje derecho de la orientación del puño**: cuando se abre por completo la mano para formar una postura plana de 5 dedos, el rayo perpendicular a la palma (hacia delante de la mano izquierda y hacia atrás desde la mano derecha)</span><span class="sxs-lookup"><span data-stu-id="a1c7f-229">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="a1c7f-230">El **eje hacia delante de la orientación del puño**: al cerrar la mano (como si contiene el controlador), el rayo que señala "reenviar" a través del tubo formado por los dedos no Thumb.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-230">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="a1c7f-231">**Eje hacia arriba de la orientación del puño**: el eje hacia arriba implícito por las definiciones derecha y hacia delante.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-231">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="a1c7f-232">Puede tener acceso al **replanteamiento del puntero** a través de [SpatialInteractionSourceState::P ropiedades:: TryGetLocation (...):: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) o [SpatialInteractionSourceState:: TryGetPointerPose (...):: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-232">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="a1c7f-233">Propiedades de entrada específicas del controlador</span><span class="sxs-lookup"><span data-stu-id="a1c7f-233">Controller-specific input properties</span></span>
<span data-ttu-id="a1c7f-234">En el caso de los controladores, SpatialInteractionSource tiene una propiedad de controlador con capacidades adicionales.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-234">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="a1c7f-235">**HasThumbstick:** Si es true, el controlador tiene un stick.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-235">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="a1c7f-236">Inspeccione la propiedad [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) de SpatialInteractionSourceState para adquirir los valores x e y del stick analógico (ThumbstickX y ThumbstickY), así como el estado presionado (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-236">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="a1c7f-237">**HasTouchpad:** Si es true, el controlador tiene un touchpad.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-237">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="a1c7f-238">Inspeccione la propiedad ControllerProperties de SpatialInteractionSourceState para adquirir los valores x e y de Touchpad (TouchpadX y Touchpad) y para saber si el usuario está tocando el panel (IsTouchpadTouched) y si está presionando el Touchpad hacia abajo (IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-238">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="a1c7f-239">**SimpleHapticsController:** La API de SimpleHapticsController para el controlador permite inspeccionar las capacidades de hápticos del controlador y también permite controlar los comentarios de hápticos.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-239">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="a1c7f-240">Tenga en cuenta que el intervalo para Touchpad y el Stick es-1 a 1 para ambos ejes (de abajo a arriba y de izquierda a derecha).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-240">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="a1c7f-241">El intervalo del desencadenador analógico, al que se tiene acceso mediante la propiedad SpatialInteractionSourceState:: SelectPressedValue, tiene un intervalo de 0 a 1.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-241">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="a1c7f-242">Un valor de 1 se correlaciona con IsSelectPressed igual a true; cualquier otro valor corresponde a IsSelectPressed siendo igual a false.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-242">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="a1c7f-243">Seguimiento de mano articulado</span><span class="sxs-lookup"><span data-stu-id="a1c7f-243">Articulated hand tracking</span></span>
<span data-ttu-id="a1c7f-244">La API de Windows Mixed Reality proporciona compatibilidad total para el seguimiento de mano articulado, por ejemplo, en HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-244">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="a1c7f-245">El seguimiento manual articulado se puede usar para implementar la manipulación directa y los modelos de entrada de punto y confirmación en las aplicaciones.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-245">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="a1c7f-246">También se puede usar para crear interacciones completamente personalizadas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-246">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="a1c7f-247">Esqueleto manual</span><span class="sxs-lookup"><span data-stu-id="a1c7f-247">Hand skeleton</span></span>
<span data-ttu-id="a1c7f-248">El seguimiento de mano articulado proporciona un conjunto de 25 esqueleto que permite muchos tipos diferentes de interacciones.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-248">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="a1c7f-249">El esqueleto proporciona 5 uniones para los dedos de índice/intermedio/anillo/pequeño, 4 uniones para el pulgar y 1 conjunto de muñecas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-249">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="a1c7f-250">La Unión de muñecas actúa como la base de la jerarquía.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-250">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="a1c7f-251">En la imagen siguiente se muestra el diseño del esqueleto.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-251">The following picture illustrates the layout of the skeleton.</span></span>

![Esqueleto manual](images/hand-skeleton.png)

<span data-ttu-id="a1c7f-253">En la mayoría de los casos, cada conjunto se denomina basándose en el hueso que representa.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-253">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="a1c7f-254">Dado que hay dos huesos en cada conjunto, usamos una Convención de nomenclatura de cada unión basada en el hueso secundario en esa ubicación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-254">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="a1c7f-255">El hueso secundario se define como el hueso más allá de la muñeca.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-255">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="a1c7f-256">Por ejemplo, la Unión "index proximal" contiene la posición inicial del proximal de índice y la orientación de dicho hueso.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-256">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="a1c7f-257">No contiene la posición final del hueso.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-257">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="a1c7f-258">Si lo necesita, lo obtendría de la Unión siguiente en la jerarquía, la Unión "índice intermedio".</span><span class="sxs-lookup"><span data-stu-id="a1c7f-258">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="a1c7f-259">Además de las 25 uniones jerárquicas, el sistema proporciona una Unión de Palm.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-259">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="a1c7f-260">La palma normalmente no se considera parte de la estructura del esqueleto.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-260">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="a1c7f-261">Solo se proporciona como una manera cómoda de obtener la posición y orientación generales de la mano.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-261">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="a1c7f-262">La siguiente información se proporciona para cada conjunto:</span><span class="sxs-lookup"><span data-stu-id="a1c7f-262">The following information is provided for each joint:</span></span>

| <span data-ttu-id="a1c7f-263">Nombre</span><span class="sxs-lookup"><span data-stu-id="a1c7f-263">Name</span></span> | <span data-ttu-id="a1c7f-264">Descripción</span><span class="sxs-lookup"><span data-stu-id="a1c7f-264">Description</span></span> |
|--- |--- |
|<span data-ttu-id="a1c7f-265">Posición</span><span class="sxs-lookup"><span data-stu-id="a1c7f-265">Position</span></span> | <span data-ttu-id="a1c7f-266">posición 3D de la Unión, disponible en cualquier sistema de coordenadas solicitado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-266">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="a1c7f-267">Orientación</span><span class="sxs-lookup"><span data-stu-id="a1c7f-267">Orientation</span></span> | <span data-ttu-id="a1c7f-268">orientación 3D del hueso, disponible en cualquier sistema de coordenadas solicitado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-268">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="a1c7f-269">Radio</span><span class="sxs-lookup"><span data-stu-id="a1c7f-269">Radius</span></span> | <span data-ttu-id="a1c7f-270">Distancia a superficie de la piel en la posición de la Unión.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-270">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="a1c7f-271">Resulta útil para optimizar interacciones directas o visualizaciones que se basan en el ancho del dedo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-271">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="a1c7f-272">Precisión</span><span class="sxs-lookup"><span data-stu-id="a1c7f-272">Accuracy</span></span> | <span data-ttu-id="a1c7f-273">Proporciona una sugerencia sobre el grado de confianza del sistema con respecto a la información de la Unión.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-273">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="a1c7f-274">Puede tener acceso a los datos del esqueleto de mano a través de una función en [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-274">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="a1c7f-275">La función se denomina [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)y devuelve un objeto denominado [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-275">The function is called [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="a1c7f-276">Si el origen no admite manos articuladas, esta función devolverá null.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-276">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="a1c7f-277">Una vez que tenga un HandPose, puede obtener datos conjuntos actuales llamando a [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), con el nombre de la Unión en la que está interesado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-277">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="a1c7f-278">Los datos se devuelven como una estructura [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) .</span><span class="sxs-lookup"><span data-stu-id="a1c7f-278">The data is returned as a [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="a1c7f-279">En el código siguiente se obtiene la posición de la sugerencia de índice.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-279">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="a1c7f-280">La variable *CurrentState* representa una instancia de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-280">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="a1c7f-281">Malla de mano</span><span class="sxs-lookup"><span data-stu-id="a1c7f-281">Hand mesh</span></span>

<span data-ttu-id="a1c7f-282">La API de seguimiento de mano articulada permite una malla de mano de triángulo totalmente deformable.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-282">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="a1c7f-283">Esta malla puede deformarse en tiempo real junto con el esqueleto manual y resulta útil para la visualización, así como técnicas de física avanzadas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-283">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="a1c7f-284">Para acceder a la malla de mano, primero debe crear un objeto [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) llamando a [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) en [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-284">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="a1c7f-285">Esto solo debe realizarse una vez por origen, normalmente la primera vez que lo ve.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-285">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="a1c7f-286">Esto significa que se llamará a esta función para crear un objeto HandMeshObserver siempre que una mano entre en el subobjeto.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-286">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="a1c7f-287">Tenga en cuenta que se trata de una función asincrónica, por lo que tendrá que tratar un poco de simultaneidad aquí.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-287">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="a1c7f-288">Una vez disponible, puede solicitar al objeto HandMeshObserver el búfer de índice de triángulo llamando a [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-288">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="a1c7f-289">Los índices no cambian el marco sobre el marco, de modo que puede obtenerlos una vez y almacenarlos en memoria caché durante el tiempo de vida del origen.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-289">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="a1c7f-290">Los índices se proporcionan en el orden de bobinado hacia la derecha.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-290">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="a1c7f-291">El siguiente código pone en marcha un STD:: Thread separado para crear el observador de la malla y extrae el búfer de índice una vez que el observador de la malla esté disponible.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-291">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="a1c7f-292">Se inicia a partir de una variable denominada *CurrentState*, que es una instancia de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) que representa una mano a la que se ha realizado un seguimiento.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-292">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="a1c7f-293">Iniciar un subproceso desasociado es solo una opción para controlar las llamadas asincrónicas.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-293">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="a1c7f-294">Como alternativa, puede usar la nueva funcionalidad de [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) compatible con C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-294">Alternatively, you could use the new [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="a1c7f-295">Una vez que tenga un objeto HandMeshObserver, debe mantenerlo durante el tiempo que su SpatialInteractionSource correspondiente esté activo.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-295">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="a1c7f-296">A continuación, cada fotograma, puede solicitarle el búfer de vértices más reciente que representa la mano llamando a [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) y pasando una instancia de [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) que representa el supuesto para el que desea los vértices.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-296">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="a1c7f-297">Cada vértice del búfer tiene una posición y un normal.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-297">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="a1c7f-298">Este es un ejemplo de cómo obtener el conjunto actual de vértices para una malla de mano.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-298">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="a1c7f-299">Al igual que antes, la variable *CurrentState* representa una instancia de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-299">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="a1c7f-300">A diferencia de las uniones de esqueleto, la API de malla de mano no permite especificar un sistema de coordenadas para los vértices.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-300">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="a1c7f-301">En su lugar, [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) especifica el sistema de coordenadas en el que se proporcionan los vértices.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-301">Instead, the [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="a1c7f-302">Después, puede obtener una transformación de malla llamando a [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) y especificando el sistema de coordenadas deseado.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-302">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="a1c7f-303">Tendrá que usar esta transformación de malla siempre que trabaje con los vértices.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-303">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="a1c7f-304">Este enfoque reduce la sobrecarga de la CPU, especialmente si solo usa la malla para fines de representación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-304">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="a1c7f-305">Miras y confirmaciones de gestos compuestos</span><span class="sxs-lookup"><span data-stu-id="a1c7f-305">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="a1c7f-306">En el caso de las aplicaciones que usan el modelo de entrada de la opción de mira y confirmación, especialmente en HoloLens (First gen), la API de entrada espacial proporciona un [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) opcional que se puede usar para habilitar los gestos compuestos basados en el evento "Select".</span><span class="sxs-lookup"><span data-stu-id="a1c7f-306">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="a1c7f-307">Al enrutar las interacciones del SpatialInteractionManager al SpatialGestureRecognizer de un holograma, las aplicaciones pueden detectar eventos de pulsación, retención, manipulación y navegación de forma uniforme a través de los dispositivos de entrada de manos, voz y espaciales, sin tener que controlar las pulsaciones y versiones de forma manual.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-307">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="a1c7f-308">SpatialGestureRecognizer solo realiza la desambiguación mínima entre el conjunto de gestos que solicite.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-308">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="a1c7f-309">Por ejemplo, si solicita simplemente TAP, el usuario puede mantener el dedo hacia abajo siempre que quiera y se siga produciendo una pulsación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-309">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="a1c7f-310">Si solicita el toque y el mantenimiento, después de que se mantenga presionado el dedo, el gesto promoverá a una suspensión y ya no se producirá una derivación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-310">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="a1c7f-311">Para usar SpatialGestureRecognizer, controle el evento [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) de SpatialInteractionManager y capte el SpatialPointerPose expuesto allí.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-311">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="a1c7f-312">Use el rayo principal del usuario de esta postura para formar una intersección con los hologramas y las mallas de superficie en el entorno del usuario, con el fin de determinar con qué está intentando interactuar el usuario.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-312">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="a1c7f-313">A continuación, enrute el SpatialInteraction de los argumentos de evento al SpatialGestureRecognizer del holograma de destino, mediante su método [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) .</span><span class="sxs-lookup"><span data-stu-id="a1c7f-313">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="a1c7f-314">Esto comienza a interpretar esa interacción según el valor de [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) establecido en el reconocedor en el momento de la creación, o en [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="a1c7f-314">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="a1c7f-315">En HoloLens (primera generación), las interacciones y gestos generalmente deben derivar sus destinatarios del encabezado del usuario, en lugar de intentar representar o interactuar directamente en la ubicación de la mano.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-315">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="a1c7f-316">Una vez que se ha iniciado una interacción, se pueden usar movimientos relativos de la mano para controlar el gesto, al igual que con la manipulación o el gesto de navegación.</span><span class="sxs-lookup"><span data-stu-id="a1c7f-316">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="a1c7f-317">Vea también</span><span class="sxs-lookup"><span data-stu-id="a1c7f-317">See also</span></span>
* [<span data-ttu-id="a1c7f-318">Control con la cabeza y los ojos de DirectX</span><span class="sxs-lookup"><span data-stu-id="a1c7f-318">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="a1c7f-319">Modelo de entrada de manipulación directa</span><span class="sxs-lookup"><span data-stu-id="a1c7f-319">Direct manipulation input model</span></span>](../../design/direct-manipulation.md)
* [<span data-ttu-id="a1c7f-320">Modelo de entrada de punto y confirmación</span><span class="sxs-lookup"><span data-stu-id="a1c7f-320">Point-and-commit input model</span></span>](../../design/point-and-commit.md)
* [<span data-ttu-id="a1c7f-321">Miran y confirman el modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="a1c7f-321">Gaze and commit input model</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="a1c7f-322">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="a1c7f-322">Motion controllers</span></span>](../../design/motion-controllers.md)
